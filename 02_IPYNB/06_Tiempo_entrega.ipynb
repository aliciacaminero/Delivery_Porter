{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delivery = pd.read_csv('../01_CSV Trabajo/df_delivery_limpio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(store_primary_category      0\n",
       " total_items                 0\n",
       " subtotal                    0\n",
       " num_distinct_items          0\n",
       " min_item_price              0\n",
       " max_item_price              0\n",
       " total_onshift_partners      0\n",
       " total_busy_partners         0\n",
       " total_outstanding_orders    0\n",
       " delivery_duration           0\n",
       " partner_density             0\n",
       " order_day                   0\n",
       " order_hour                  0\n",
       " order_period                0\n",
       " busy_ratio                  0\n",
       " avg_item_price              0\n",
       " order_size                  0\n",
       " grouped_category            0\n",
       " dtype: int64,\n",
       " store_primary_category       object\n",
       " total_items                   int64\n",
       " subtotal                      int64\n",
       " num_distinct_items            int64\n",
       " min_item_price                int64\n",
       " max_item_price                int64\n",
       " total_onshift_partners      float64\n",
       " total_busy_partners         float64\n",
       " total_outstanding_orders    float64\n",
       " delivery_duration           float64\n",
       " partner_density             float64\n",
       " order_day                    object\n",
       " order_hour                    int64\n",
       " order_period                 object\n",
       " busy_ratio                  float64\n",
       " avg_item_price              float64\n",
       " order_size                   object\n",
       " grouped_category             object\n",
       " dtype: object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobar los valores nulos en el dataframe\n",
    "nulos = df_delivery.isnull().sum()\n",
    "\n",
    "# Verificar los tipos de datos de cada columna\n",
    "tipos_datos = df_delivery.dtypes\n",
    "\n",
    "# Mostrar los resultados\n",
    "nulos, tipos_datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_items                    int64\n",
       "subtotal                       int64\n",
       "num_distinct_items             int64\n",
       "min_item_price                 int64\n",
       "max_item_price                 int64\n",
       "total_onshift_partners       float64\n",
       "total_busy_partners          float64\n",
       "total_outstanding_orders     float64\n",
       "delivery_duration            float64\n",
       "partner_density              float64\n",
       "order_day                   category\n",
       "order_hour                     int64\n",
       "order_period                category\n",
       "busy_ratio                   float64\n",
       "avg_item_price               float64\n",
       "order_size                  category\n",
       "grouped_category            category\n",
       "dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar la columna irrelevante 'store_primary_category'\n",
    "df_delivery_cleaned = df_delivery.drop(columns=['store_primary_category'])\n",
    "\n",
    "# Convertir las columnas categóricas a tipo categoría\n",
    "df_delivery_cleaned['order_day'] = df_delivery_cleaned['order_day'].astype('category')\n",
    "df_delivery_cleaned['order_period'] = df_delivery_cleaned['order_period'].astype('category')\n",
    "df_delivery_cleaned['order_size'] = df_delivery_cleaned['order_size'].astype('category')\n",
    "df_delivery_cleaned['grouped_category'] = df_delivery_cleaned['grouped_category'].astype('category')\n",
    "\n",
    "# Verificar los cambios en los tipos de datos\n",
    "df_delivery_cleaned.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Corregir el uso de OneHotEncoder para versiones compatibles de scikit-learn\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m encoder \u001b[38;5;241m=\u001b[39m \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Transformar las columnas categóricas\u001b[39;00m\n\u001b[1;32m      5\u001b[0m order_day_encoded \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mfit_transform(df_delivery_cleaned[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_day\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'sparse'"
     ]
    }
   ],
   "source": [
    "# Corregir el uso de OneHotEncoder para versiones compatibles de scikit-learn\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Transformar las columnas categóricas\n",
    "order_day_encoded = encoder.fit_transform(df_delivery_cleaned[['order_day']])\n",
    "order_period_encoded = encoder.fit_transform(df_delivery_cleaned[['order_period']])\n",
    "order_size_encoded = encoder.fit_transform(df_delivery_cleaned[['order_size']])\n",
    "grouped_category_encoded = encoder.fit_transform(df_delivery_cleaned[['grouped_category']])\n",
    "\n",
    "# Normalizar las columnas numéricas\n",
    "numerical_columns = ['total_items', 'subtotal', 'num_distinct_items', 'min_item_price', 'max_item_price',\n",
    "                     'total_onshift_partners', 'total_busy_partners', 'total_outstanding_orders', \n",
    "                     'partner_density', 'order_hour', 'busy_ratio', 'avg_item_price']\n",
    "scaler = StandardScaler()\n",
    "numerical_data_scaled = scaler.fit_transform(df_delivery_cleaned[numerical_columns])\n",
    "\n",
    "# Concatenar todos los datos preprocesados\n",
    "X_processed = pd.concat([pd.DataFrame(order_day_encoded), \n",
    "                         pd.DataFrame(order_period_encoded),\n",
    "                         pd.DataFrame(order_size_encoded), \n",
    "                         pd.DataFrame(grouped_category_encoded), \n",
    "                         pd.DataFrame(numerical_data_scaled)], axis=1)\n",
    "\n",
    "# Variable objetivo (delivery_duration)\n",
    "y_processed = df_delivery_cleaned['delivery_duration']\n",
    "\n",
    "# Mostrar el dataframe preprocesado\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Datos Preprocesados para Análisis\", dataframe=df_delivery_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(total_items                  0\n",
       " subtotal                     0\n",
       " num_distinct_items           0\n",
       " min_item_price               0\n",
       " max_item_price               0\n",
       " total_onshift_partners       0\n",
       " total_busy_partners          0\n",
       " total_outstanding_orders     0\n",
       " partner_density             14\n",
       " order_hour                   0\n",
       " busy_ratio                   6\n",
       " avg_item_price               0\n",
       " dtype: int64,\n",
       " total_items                  411.0\n",
       " subtotal                    6405.0\n",
       " num_distinct_items            15.0\n",
       " min_item_price              6400.0\n",
       " max_item_price              6400.0\n",
       " total_onshift_partners       171.0\n",
       " total_busy_partners          154.0\n",
       " total_outstanding_orders     278.0\n",
       " partner_density                inf\n",
       " order_hour                    23.0\n",
       " busy_ratio                     inf\n",
       " avg_item_price              6400.0\n",
       " dtype: float64,\n",
       " total_items                  1.0\n",
       " subtotal                     0.0\n",
       " num_distinct_items           1.0\n",
       " min_item_price             -86.0\n",
       " max_item_price               0.0\n",
       " total_onshift_partners      -4.0\n",
       " total_busy_partners         -5.0\n",
       " total_outstanding_orders    -6.0\n",
       " partner_density             -inf\n",
       " order_hour                   0.0\n",
       " busy_ratio                  -8.0\n",
       " avg_item_price               0.0\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Verificar si hay valores infinitos o extremadamente grandes en las columnas numéricas\n",
    "infinity_check = np.isinf(df_delivery_cleaned[numerical_columns]).sum()\n",
    "max_values = df_delivery_cleaned[numerical_columns].max()\n",
    "min_values = df_delivery_cleaned[numerical_columns].min()\n",
    "\n",
    "infinity_check, max_values, min_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(total_items                  411.0\n",
       " subtotal                    6405.0\n",
       " num_distinct_items            15.0\n",
       " min_item_price              6400.0\n",
       " max_item_price              6400.0\n",
       " total_onshift_partners       171.0\n",
       " total_busy_partners          154.0\n",
       " total_outstanding_orders     278.0\n",
       " partner_density                inf\n",
       " order_hour                    23.0\n",
       " busy_ratio                     inf\n",
       " avg_item_price              6400.0\n",
       " dtype: float64,\n",
       " total_items                  1.000000\n",
       " subtotal                     0.000000\n",
       " num_distinct_items           1.000000\n",
       " min_item_price               1.000000\n",
       " max_item_price              52.000000\n",
       " total_onshift_partners       1.000000\n",
       " total_busy_partners          1.000000\n",
       " total_outstanding_orders     1.000000\n",
       " partner_density              0.020833\n",
       " order_hour                   0.000000\n",
       " busy_ratio                  -8.000000\n",
       " avg_item_price               7.579075\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reemplazar los valores extremos o cercanos a cero por la mediana de cada columna correspondiente\n",
    "df_delivery_cleaned['min_item_price'] = df_delivery_cleaned['min_item_price'].apply(lambda x: df_delivery_cleaned['min_item_price'].median() if x <= 0 else x)\n",
    "df_delivery_cleaned['max_item_price'] = df_delivery_cleaned['max_item_price'].apply(lambda x: df_delivery_cleaned['max_item_price'].median() if x <= 0 else x)\n",
    "df_delivery_cleaned['total_onshift_partners'] = df_delivery_cleaned['total_onshift_partners'].apply(lambda x: df_delivery_cleaned['total_onshift_partners'].median() if x <= 0 else x)\n",
    "df_delivery_cleaned['total_busy_partners'] = df_delivery_cleaned['total_busy_partners'].apply(lambda x: df_delivery_cleaned['total_busy_partners'].median() if x <= 0 else x)\n",
    "df_delivery_cleaned['total_outstanding_orders'] = df_delivery_cleaned['total_outstanding_orders'].apply(lambda x: df_delivery_cleaned['total_outstanding_orders'].median() if x <= 0 else x)\n",
    "df_delivery_cleaned['partner_density'] = df_delivery_cleaned['partner_density'].apply(lambda x: df_delivery_cleaned['partner_density'].median() if x <= 0 else x)\n",
    "df_delivery_cleaned['avg_item_price'] = df_delivery_cleaned['avg_item_price'].apply(lambda x: df_delivery_cleaned['avg_item_price'].median() if x <= 0 else x)\n",
    "\n",
    "# Verificar los valores máximos y mínimos después de reemplazar\n",
    "max_values = df_delivery_cleaned[numerical_columns].max()\n",
    "min_values = df_delivery_cleaned[numerical_columns].min()\n",
    "\n",
    "max_values, min_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(total_items                  411.0\n",
       " subtotal                    6405.0\n",
       " num_distinct_items            15.0\n",
       " min_item_price              6400.0\n",
       " max_item_price              6400.0\n",
       " total_onshift_partners       171.0\n",
       " total_busy_partners          154.0\n",
       " total_outstanding_orders     278.0\n",
       " partner_density               34.0\n",
       " order_hour                    23.0\n",
       " busy_ratio                    29.0\n",
       " avg_item_price              6400.0\n",
       " dtype: float64,\n",
       " total_items                  1.000000\n",
       " subtotal                     0.000000\n",
       " num_distinct_items           1.000000\n",
       " min_item_price               1.000000\n",
       " max_item_price              52.000000\n",
       " total_onshift_partners       1.000000\n",
       " total_busy_partners          1.000000\n",
       " total_outstanding_orders     1.000000\n",
       " partner_density              0.020833\n",
       " order_hour                   0.000000\n",
       " busy_ratio                  -0.000000\n",
       " avg_item_price               7.579075\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reemplazar valores negativos con la mediana de cada columna correspondiente\n",
    "df_delivery_cleaned['total_items'] = df_delivery_cleaned['total_items'].apply(lambda x: df_delivery_cleaned['total_items'].median() if x < 0 else x)\n",
    "df_delivery_cleaned['subtotal'] = df_delivery_cleaned['subtotal'].apply(lambda x: df_delivery_cleaned['subtotal'].median() if x < 0 else x)\n",
    "df_delivery_cleaned['num_distinct_items'] = df_delivery_cleaned['num_distinct_items'].apply(lambda x: df_delivery_cleaned['num_distinct_items'].median() if x < 0 else x)\n",
    "df_delivery_cleaned['min_item_price'] = df_delivery_cleaned['min_item_price'].apply(lambda x: df_delivery_cleaned['min_item_price'].median() if x < 0 else x)\n",
    "df_delivery_cleaned['max_item_price'] = df_delivery_cleaned['max_item_price'].apply(lambda x: df_delivery_cleaned['max_item_price'].median() if x < 0 else x)\n",
    "df_delivery_cleaned['total_onshift_partners'] = df_delivery_cleaned['total_onshift_partners'].apply(lambda x: df_delivery_cleaned['total_onshift_partners'].median() if x < 0 else x)\n",
    "df_delivery_cleaned['total_busy_partners'] = df_delivery_cleaned['total_busy_partners'].apply(lambda x: df_delivery_cleaned['total_busy_partners'].median() if x < 0 else x)\n",
    "df_delivery_cleaned['total_outstanding_orders'] = df_delivery_cleaned['total_outstanding_orders'].apply(lambda x: df_delivery_cleaned['total_outstanding_orders'].median() if x < 0 else x)\n",
    "df_delivery_cleaned['partner_density'] = df_delivery_cleaned['partner_density'].apply(lambda x: df_delivery_cleaned['partner_density'].median() if x < 0 or np.isinf(x) else x)\n",
    "df_delivery_cleaned['busy_ratio'] = df_delivery_cleaned['busy_ratio'].apply(lambda x: df_delivery_cleaned['busy_ratio'].median() if x < 0 or np.isinf(x) else x)\n",
    "df_delivery_cleaned['avg_item_price'] = df_delivery_cleaned['avg_item_price'].apply(lambda x: df_delivery_cleaned['avg_item_price'].median() if x < 0 else x)\n",
    "\n",
    "# Verificar si ahora no hay valores negativos ni infinitos\n",
    "max_values = df_delivery_cleaned[numerical_columns].max()\n",
    "min_values = df_delivery_cleaned[numerical_columns].min()\n",
    "\n",
    "max_values, min_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(798844.4922242219, 696.4162912180512, 0.14438267690426454)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Inicializar el modelo de Random Forest\n",
    "modelo_rf = RandomForestRegressor(random_state=42, n_estimators=100, max_depth=5)\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_rf = modelo_rf.predict(X_test)\n",
    "\n",
    "# Calcular MSE, MAE y R² para el modelo de Random Forest\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "mse_rf, mae_rf, r2_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luismgl/Library/Python/3.9/lib/python/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/luismgl/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "405 fits failed out of a total of 1215.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "219 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luismgl/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/luismgl/Library/Python/3.9/lib/python/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/luismgl/Library/Python/3.9/lib/python/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/luismgl/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "186 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luismgl/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/luismgl/Library/Python/3.9/lib/python/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/luismgl/Library/Python/3.9/lib/python/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/luismgl/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/luismgl/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [             nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan -764956.46666578\n",
      " -763740.88062855 -763746.56781105 -764787.17693506 -763689.74189395\n",
      " -763765.24712324 -764650.52608182 -763682.90214817 -763895.9665692\n",
      " -764727.84075757 -763701.08519079 -763748.95607821 -764624.3954911\n",
      " -763613.97490483 -763724.35296974 -764486.73301773 -763522.08137247\n",
      " -763805.57668281 -764545.46230176 -763536.84497009 -763798.68574524\n",
      " -764545.46230176 -763536.84497009 -763798.68574524 -764538.7890087\n",
      " -763535.38590152 -763816.20042369 -775998.56598528 -774096.7456328\n",
      " -771854.36609076 -776059.51078484 -774116.94033746 -771620.42250312\n",
      " -776828.74034952 -774464.09177519 -771695.31412224 -775908.56426385\n",
      " -774162.99656955 -771654.97217021 -775983.38556411 -774164.32523909\n",
      " -771714.97662939 -776753.32776903 -774520.4831734  -771794.57761918\n",
      " -776004.70534951 -774109.09668155 -771886.7675478  -776004.70534951\n",
      " -774109.09668155 -771886.7675478  -776666.69798125 -774444.09156069\n",
      " -772094.88960001              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      " -709935.35685134 -708742.65816909 -708216.18736213 -709432.03847804\n",
      " -708372.29857108 -708153.12130781 -709603.88517317 -708728.78025612\n",
      " -708392.23416421 -709841.72332435 -708935.39699844 -708150.15979005\n",
      " -708816.65297224 -708264.59599443 -707612.3134481  -709822.78498356\n",
      " -708574.45754016 -708124.33579442 -709417.47189425 -708434.09053061\n",
      " -708181.94180294 -709417.47189425 -708434.09053061 -708181.94180294\n",
      " -709060.28705936 -708273.19581324 -708049.22763469 -716227.53945215\n",
      " -714510.43591266 -713741.17446939 -716689.81900492 -715103.64627853\n",
      " -714037.71627625 -715588.65301569 -714345.58217782 -713630.69869644\n",
      " -715732.01068709 -714573.69678838 -713779.27991377 -715894.26905615\n",
      " -714828.98167118 -713882.72125114 -716883.8681615  -714707.2685263\n",
      " -713840.91241993 -717033.5927357  -715024.43987191 -713961.65859382\n",
      " -717033.5927357  -715024.43987191 -713961.65859382 -716367.32710936\n",
      " -714408.71338832 -713750.35838016              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan -690338.92040437 -687694.11235957 -686563.2464559\n",
      " -690985.49812436 -688352.28405897 -687060.24222507 -690103.25537272\n",
      " -687929.88158085 -686951.75553509 -690226.3095292  -687919.7718348\n",
      " -686862.09742404 -689898.2333629  -687741.6077504  -686723.79188812\n",
      " -689864.73453576 -687819.16712091 -686874.71126466 -690187.46590902\n",
      " -688092.58126947 -687049.10951881 -690187.46590902 -688092.58126947\n",
      " -687049.10951881 -689729.6951786  -687933.89046162 -687175.30399752\n",
      " -693620.81683647 -691005.4416005  -689798.4532981  -692998.57670384\n",
      " -690699.80497654 -689612.14822874 -693173.98970865 -691263.07372283\n",
      " -689941.69843826 -692469.25963924 -690322.99626336 -689341.18608462\n",
      " -692340.30103706 -690648.53137411 -690084.74057786 -692527.85011191\n",
      " -690538.96094504 -689840.94748639 -692911.27636391 -690759.275958\n",
      " -690025.34889381 -692911.27636391 -690759.275958   -690025.34889381\n",
      " -692844.77059216 -691201.03920103 -690468.16739181]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 15,\n",
       "  'max_features': 'sqrt',\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_samples_split': 2,\n",
       "  'n_estimators': 200},\n",
       " 679652.905898803,\n",
       " 638.5535686208785,\n",
       " 0.2720450530237265)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Cargo datos nuevos el archivo con los datos\n",
    "df_delivery = pd.read_csv('../01_CSV Trabajo/data_analisis.csv')\n",
    "\n",
    "# Transformar las columnas categóricas\n",
    "order_day_encoded = encoder.fit_transform(df_delivery[['order_day']])\n",
    "order_period_encoded = encoder.fit_transform(df_delivery[['order_period']])\n",
    "order_size_encoded = encoder.fit_transform(df_delivery[['order_size']])\n",
    "grouped_category_encoded = encoder.fit_transform(df_delivery[['grouped_category']])\n",
    "\n",
    "# Normalizar las columnas numéricas\n",
    "numerical_data_scaled = scaler.fit_transform(df_delivery[numerical_columns])\n",
    "\n",
    "# Concatenar todos los datos preprocesados\n",
    "X_processed = pd.concat([pd.DataFrame(order_day_encoded), \n",
    "                         pd.DataFrame(order_period_encoded),\n",
    "                         pd.DataFrame(order_size_encoded), \n",
    "                         pd.DataFrame(grouped_category_encoded), \n",
    "                         pd.DataFrame(numerical_data_scaled)], axis=1)\n",
    "\n",
    "# Variable objetivo (delivery_duration)\n",
    "y_processed = df_delivery['delivery_duration']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y_processed, test_size=0.2, random_state=42)\n",
    "\n",
    "# Volver a realizar el ajuste de hiperparámetros\n",
    "\n",
    "# Definir el espacio de búsqueda para los hiperparámetros\n",
    "parametros = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Inicializar el modelo de Random Forest\n",
    "modelo_rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Inicializar GridSearchCV con validación cruzada\n",
    "grid_search = GridSearchCV(estimator=modelo_rf, param_grid=parametros, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Entrenar el modelo con GridSearch\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores parámetros encontrados\n",
    "mejores_parametros = grid_search.best_params_\n",
    "\n",
    "# Evaluar el modelo con los mejores parámetros\n",
    "mejor_modelo = grid_search.best_estimator_\n",
    "y_pred_rf_ajustado = mejor_modelo.predict(X_test)\n",
    "\n",
    "# Calcular MSE, MAE y R² para el modelo ajustado\n",
    "\n",
    "mse_rf_ajustado = mean_squared_error(y_test, y_pred_rf_ajustado)\n",
    "mae_rf_ajustado = mean_absolute_error(y_test, y_pred_rf_ajustado)\n",
    "r2_rf_ajustado = r2_score(y_test, y_pred_rf_ajustado)\n",
    "\n",
    "mejores_parametros, mse_rf_ajustado, mae_rf_ajustado, r2_rf_ajustado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_items</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>num_distinct_items</th>\n",
       "      <th>min_item_price</th>\n",
       "      <th>max_item_price</th>\n",
       "      <th>total_onshift_partners</th>\n",
       "      <th>total_busy_partners</th>\n",
       "      <th>total_outstanding_orders</th>\n",
       "      <th>delivery_duration</th>\n",
       "      <th>partner_density</th>\n",
       "      <th>order_day</th>\n",
       "      <th>order_hour</th>\n",
       "      <th>order_period</th>\n",
       "      <th>busy_ratio</th>\n",
       "      <th>avg_item_price</th>\n",
       "      <th>order_size</th>\n",
       "      <th>grouped_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3441</td>\n",
       "      <td>4</td>\n",
       "      <td>557.0</td>\n",
       "      <td>1239</td>\n",
       "      <td>33.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3779.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>Friday</td>\n",
       "      <td>22</td>\n",
       "      <td>Night</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>860.25</td>\n",
       "      <td>Medium</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4024.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>21</td>\n",
       "      <td>Evening</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1900.00</td>\n",
       "      <td>Small</td>\n",
       "      <td>Mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4771</td>\n",
       "      <td>3</td>\n",
       "      <td>820.0</td>\n",
       "      <td>1604</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1586.0</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>Night</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1192.75</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1525</td>\n",
       "      <td>1</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>1525</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2273.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>3</td>\n",
       "      <td>Night</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1525.00</td>\n",
       "      <td>Small</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3620</td>\n",
       "      <td>2</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2988.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2</td>\n",
       "      <td>Night</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1810.00</td>\n",
       "      <td>Small</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_items  subtotal  num_distinct_items  min_item_price  max_item_price  \\\n",
       "0            4      3441                   4           557.0            1239   \n",
       "1            1      1900                   1          1400.0            1400   \n",
       "2            4      4771                   3           820.0            1604   \n",
       "3            1      1525                   1          1525.0            1525   \n",
       "4            2      3620                   2          1425.0            2195   \n",
       "\n",
       "   total_onshift_partners  total_busy_partners  total_outstanding_orders  \\\n",
       "0                    33.0                 14.0                      21.0   \n",
       "1                     1.0                  2.0                       2.0   \n",
       "2                     8.0                  6.0                      18.0   \n",
       "3                     5.0                  6.0                       8.0   \n",
       "4                     5.0                  5.0                       7.0   \n",
       "\n",
       "   delivery_duration  partner_density order_day  order_hour order_period  \\\n",
       "0             3779.0         1.500000    Friday          22        Night   \n",
       "1             4024.0         0.333333   Tuesday          21      Evening   \n",
       "2             1586.0         0.421053    Monday           0        Night   \n",
       "3             2273.0         0.555556  Thursday           3        Night   \n",
       "4             2988.0         0.625000   Tuesday           2        Night   \n",
       "\n",
       "   busy_ratio  avg_item_price order_size grouped_category  \n",
       "0    0.411765          860.25     Medium         American  \n",
       "1    1.000000         1900.00      Small          Mexican  \n",
       "2    0.666667         1192.75     Medium           Indian  \n",
       "3    1.000000         1525.00      Small          Italian  \n",
       "4    0.833333         1810.00      Small          Italian  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el archivo con los datos\n",
    "df_analisis = pd.read_csv('../01_CSV Trabajo/data_analisis.csv')\n",
    "\n",
    "# Mostrar las primeras filas del dataframe para revisar su estructura\n",
    "df_analisis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_items</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>num_distinct_items</th>\n",
       "      <th>min_item_price</th>\n",
       "      <th>max_item_price</th>\n",
       "      <th>total_onshift_partners</th>\n",
       "      <th>total_busy_partners</th>\n",
       "      <th>total_outstanding_orders</th>\n",
       "      <th>delivery_duration</th>\n",
       "      <th>partner_density</th>\n",
       "      <th>order_day</th>\n",
       "      <th>order_hour</th>\n",
       "      <th>order_period</th>\n",
       "      <th>busy_ratio</th>\n",
       "      <th>avg_item_price</th>\n",
       "      <th>order_size</th>\n",
       "      <th>grouped_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45222</th>\n",
       "      <td>3</td>\n",
       "      <td>4627</td>\n",
       "      <td>3</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>1799</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3706.0</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2</td>\n",
       "      <td>Night</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>1542.333333</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100397</th>\n",
       "      <td>3</td>\n",
       "      <td>3275</td>\n",
       "      <td>3</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>123.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>2994.0</td>\n",
       "      <td>0.778481</td>\n",
       "      <td>Friday</td>\n",
       "      <td>3</td>\n",
       "      <td>Night</td>\n",
       "      <td>0.814516</td>\n",
       "      <td>1091.666667</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63589</th>\n",
       "      <td>1</td>\n",
       "      <td>1070</td>\n",
       "      <td>1</td>\n",
       "      <td>695.0</td>\n",
       "      <td>695</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2976.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>22</td>\n",
       "      <td>Night</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1070.000000</td>\n",
       "      <td>Small</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118513</th>\n",
       "      <td>3</td>\n",
       "      <td>4240</td>\n",
       "      <td>3</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>1650</td>\n",
       "      <td>107.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>4313.0</td>\n",
       "      <td>0.543147</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>3</td>\n",
       "      <td>Night</td>\n",
       "      <td>1.027778</td>\n",
       "      <td>1413.333333</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Desserts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48796</th>\n",
       "      <td>8</td>\n",
       "      <td>5400</td>\n",
       "      <td>4</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2200</td>\n",
       "      <td>36.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>Night</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>675.000000</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total_items  subtotal  num_distinct_items  min_item_price  \\\n",
       "45222             3      4627                   3          1029.0   \n",
       "100397            3      3275                   3           225.0   \n",
       "63589             1      1070                   1           695.0   \n",
       "118513            3      4240                   3          1095.0   \n",
       "48796             8      5400                   4           250.0   \n",
       "\n",
       "        max_item_price  total_onshift_partners  total_busy_partners  \\\n",
       "45222             1799                    34.0                 33.0   \n",
       "100397            1500                   123.0                101.0   \n",
       "63589              695                    15.0                 16.0   \n",
       "118513            1650                   107.0                111.0   \n",
       "48796             2200                    36.0                 27.0   \n",
       "\n",
       "        total_outstanding_orders  delivery_duration  partner_density  \\\n",
       "45222                       38.0             3706.0         0.871795   \n",
       "100397                     157.0             2994.0         0.778481   \n",
       "63589                       19.0             2976.0         0.750000   \n",
       "118513                     196.0             4313.0         0.543147   \n",
       "48796                       27.0             2480.0         1.285714   \n",
       "\n",
       "        order_day  order_hour order_period  busy_ratio  avg_item_price  \\\n",
       "45222    Thursday           2        Night    0.942857     1542.333333   \n",
       "100397     Friday           3        Night    0.814516     1091.666667   \n",
       "63589   Wednesday          22        Night    1.000000     1070.000000   \n",
       "118513     Sunday           3        Night    1.027778     1413.333333   \n",
       "48796   Wednesday           0        Night    0.729730      675.000000   \n",
       "\n",
       "       order_size grouped_category  \n",
       "45222      Medium          Italian  \n",
       "100397     Medium            Other  \n",
       "63589       Small            Other  \n",
       "118513     Medium         Desserts  \n",
       "48796      Medium          Italian  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tomar una muestra más pequeña de los datos para evitar problemas de memoria\n",
    "df_sample = df_analisis.sample(frac=0.1, random_state=42)  # Tomamos el 10% de los datos\n",
    "\n",
    "# Mostrar las primeras filas del dataframe con la muestra más pequeña\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_items                   int64\n",
       "subtotal                      int64\n",
       "num_distinct_items            int64\n",
       "min_item_price              float64\n",
       "max_item_price                int64\n",
       "total_onshift_partners      float64\n",
       "total_busy_partners         float64\n",
       "total_outstanding_orders    float64\n",
       "delivery_duration           float64\n",
       "partner_density             float64\n",
       "order_day                    object\n",
       "order_hour                    int64\n",
       "order_period                 object\n",
       "busy_ratio                  float64\n",
       "avg_item_price              float64\n",
       "order_size                   object\n",
       "grouped_category             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_items</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>num_distinct_items</th>\n",
       "      <th>min_item_price</th>\n",
       "      <th>max_item_price</th>\n",
       "      <th>total_onshift_partners</th>\n",
       "      <th>total_busy_partners</th>\n",
       "      <th>total_outstanding_orders</th>\n",
       "      <th>delivery_duration</th>\n",
       "      <th>partner_density</th>\n",
       "      <th>order_day</th>\n",
       "      <th>order_hour</th>\n",
       "      <th>order_period</th>\n",
       "      <th>busy_ratio</th>\n",
       "      <th>avg_item_price</th>\n",
       "      <th>order_size</th>\n",
       "      <th>grouped_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45222</th>\n",
       "      <td>3</td>\n",
       "      <td>4627</td>\n",
       "      <td>3</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>1799</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3706.0</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2</td>\n",
       "      <td>Night</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>1542.333333</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100397</th>\n",
       "      <td>3</td>\n",
       "      <td>3275</td>\n",
       "      <td>3</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>123.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>2994.0</td>\n",
       "      <td>0.778481</td>\n",
       "      <td>Friday</td>\n",
       "      <td>3</td>\n",
       "      <td>Night</td>\n",
       "      <td>0.814516</td>\n",
       "      <td>1091.666667</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63589</th>\n",
       "      <td>1</td>\n",
       "      <td>1070</td>\n",
       "      <td>1</td>\n",
       "      <td>695.0</td>\n",
       "      <td>695</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2976.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>22</td>\n",
       "      <td>Night</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1070.000000</td>\n",
       "      <td>Small</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118513</th>\n",
       "      <td>3</td>\n",
       "      <td>4240</td>\n",
       "      <td>3</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>1650</td>\n",
       "      <td>107.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>4313.0</td>\n",
       "      <td>0.543147</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>3</td>\n",
       "      <td>Night</td>\n",
       "      <td>1.027778</td>\n",
       "      <td>1413.333333</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Desserts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48796</th>\n",
       "      <td>8</td>\n",
       "      <td>5400</td>\n",
       "      <td>4</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2200</td>\n",
       "      <td>36.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>Night</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>675.000000</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total_items  subtotal  num_distinct_items  min_item_price  \\\n",
       "45222             3      4627                   3          1029.0   \n",
       "100397            3      3275                   3           225.0   \n",
       "63589             1      1070                   1           695.0   \n",
       "118513            3      4240                   3          1095.0   \n",
       "48796             8      5400                   4           250.0   \n",
       "\n",
       "        max_item_price  total_onshift_partners  total_busy_partners  \\\n",
       "45222             1799                    34.0                 33.0   \n",
       "100397            1500                   123.0                101.0   \n",
       "63589              695                    15.0                 16.0   \n",
       "118513            1650                   107.0                111.0   \n",
       "48796             2200                    36.0                 27.0   \n",
       "\n",
       "        total_outstanding_orders  delivery_duration  partner_density  \\\n",
       "45222                       38.0             3706.0         0.871795   \n",
       "100397                     157.0             2994.0         0.778481   \n",
       "63589                       19.0             2976.0         0.750000   \n",
       "118513                     196.0             4313.0         0.543147   \n",
       "48796                       27.0             2480.0         1.285714   \n",
       "\n",
       "        order_day  order_hour order_period  busy_ratio  avg_item_price  \\\n",
       "45222    Thursday           2        Night    0.942857     1542.333333   \n",
       "100397     Friday           3        Night    0.814516     1091.666667   \n",
       "63589   Wednesday          22        Night    1.000000     1070.000000   \n",
       "118513     Sunday           3        Night    1.027778     1413.333333   \n",
       "48796   Wednesday           0        Night    0.729730      675.000000   \n",
       "\n",
       "       order_size grouped_category  \n",
       "45222      Medium          Italian  \n",
       "100397     Medium            Other  \n",
       "63589       Small            Other  \n",
       "118513     Medium         Desserts  \n",
       "48796      Medium          Italian  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tomar una muestra más pequeña del conjunto de datos para evitar problemas de memoria\n",
    "df_sample_small = df_analisis.sample(frac=0.1, random_state=42)  # Tomar el 10% de los datos\n",
    "\n",
    "# Verificar la estructura de la muestra\n",
    "df_sample_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(715594.0172925747, 661.4014816703027, 0.23539837592006319)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Codificar las columnas categóricas (order_day, order_period, grouped_category) utilizando OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Transformar las columnas categóricas\n",
    "order_day_encoded = encoder.fit_transform(df_sample[['order_day']])\n",
    "order_period_encoded = encoder.fit_transform(df_sample[['order_period']])\n",
    "grouped_category_encoded = encoder.fit_transform(df_sample[['grouped_category']])\n",
    "\n",
    "# Normalizar las columnas numéricas\n",
    "numerical_columns = ['total_items', 'subtotal', 'num_distinct_items', 'min_item_price', 'max_item_price',\n",
    "                     'total_onshift_partners', 'total_busy_partners', 'total_outstanding_orders', \n",
    "                     'order_hour', 'busy_ratio', 'avg_item_price']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numerical_data_scaled = scaler.fit_transform(df_sample[numerical_columns])\n",
    "\n",
    "# Concatenar todas las características preprocesadas\n",
    "X_processed = pd.concat([pd.DataFrame(order_day_encoded), \n",
    "                         pd.DataFrame(order_period_encoded), \n",
    "                         pd.DataFrame(grouped_category_encoded), \n",
    "                         pd.DataFrame(numerical_data_scaled)], axis=1)\n",
    "\n",
    "# Variable objetivo (delivery_duration)\n",
    "y_processed = df_sample['delivery_duration']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y_processed, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar el modelo de Random Forest\n",
    "modelo_rf = RandomForestRegressor(random_state=42, n_estimators=100, max_depth=10)\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_rf = modelo_rf.predict(X_test)\n",
    "\n",
    "# Calcular MSE, MAE y R² para el modelo de Random Forest\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "mse_rf, mae_rf, r2_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_items', 'subtotal', 'num_distinct_items', 'min_item_price',\n",
       "       'max_item_price', 'total_onshift_partners', 'total_busy_partners',\n",
       "       'total_outstanding_orders', 'delivery_duration', 'partner_density',\n",
       "       'order_day', 'order_hour', 'order_period', 'busy_ratio',\n",
       "       'avg_item_price', 'order_size', 'grouped_category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analisis.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grouped_category            0\n",
       "total_onshift_partners      0\n",
       "total_busy_partners         0\n",
       "total_outstanding_orders    0\n",
       "order_hour                  0\n",
       "order_day                   0\n",
       "delivery_duration           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrar las columnas necesarias para el modelo\n",
    "caracteristicas_relevantes = [\n",
    "    'grouped_category', 'total_onshift_partners', 'total_busy_partners', 'total_outstanding_orders', \n",
    "    'order_hour', 'order_day'\n",
    "]\n",
    "\n",
    "# Filtrar el dataframe para que solo contenga las columnas necesarias\n",
    "df_relevantes = df_analisis[caracteristicas_relevantes + ['delivery_duration']]\n",
    "\n",
    "# Comprobar si hay valores nulos o atípicos en los datos\n",
    "df_relevantes.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    162381.000000\n",
       "mean       2704.661309\n",
       "std         862.780617\n",
       "min         297.000000\n",
       "25%        2065.000000\n",
       "50%        2592.000000\n",
       "75%        3244.000000\n",
       "max        5154.000000\n",
       "Name: delivery_duration, dtype: float64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identificar y eliminar outliers en 'delivery_duration' usando el método de IQR\n",
    "Q1 = df_relevantes['delivery_duration'].quantile(0.25)\n",
    "Q3 = df_relevantes['delivery_duration'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calcular los límites inferior y superior para los outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filtrar los datos eliminando los outliers\n",
    "df_cleaned = df_relevantes[(df_relevantes['delivery_duration'] >= lower_bound) & (df_relevantes['delivery_duration'] <= upper_bound)]\n",
    "\n",
    "# Verificar que los outliers han sido eliminados\n",
    "df_cleaned['delivery_duration'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(577283.4462228369, 605.0270788340529, 0.2242878209817858)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Codificar las columnas categóricas (order_day, grouped_category) utilizando OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Transformar las columnas categóricas\n",
    "order_day_encoded = encoder.fit_transform(df_cleaned[['order_day']])\n",
    "grouped_category_encoded = encoder.fit_transform(df_cleaned[['grouped_category']])\n",
    "\n",
    "# Normalizar las columnas numéricas\n",
    "numerical_columns = ['total_onshift_partners', 'total_busy_partners', 'total_outstanding_orders', 'order_hour']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numerical_data_scaled = scaler.fit_transform(df_cleaned[numerical_columns])\n",
    "\n",
    "# Concatenar todas las características preprocesadas\n",
    "X_processed = pd.concat([pd.DataFrame(order_day_encoded), \n",
    "                         pd.DataFrame(grouped_category_encoded), \n",
    "                         pd.DataFrame(numerical_data_scaled)], axis=1)\n",
    "\n",
    "# Variable objetivo (delivery_duration)\n",
    "y_processed = df_cleaned['delivery_duration']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y_processed, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar el modelo de Random Forest\n",
    "modelo_rf = RandomForestRegressor(random_state=42, n_estimators=100, max_depth=10)\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_rf = modelo_rf.predict(X_test)\n",
    "\n",
    "# Calcular MSE, MAE y R² para el modelo de Random Forest\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "mse_rf, mae_rf, r2_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(577283.4462228369, 605.0270788340529, 0.2242878209817858)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Codificar las columnas categóricas (order_day, grouped_category) utilizando OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Transformar las columnas categóricas\n",
    "order_day_encoded = encoder.fit_transform(df_cleaned[['order_day']])\n",
    "grouped_category_encoded = encoder.fit_transform(df_cleaned[['grouped_category']])\n",
    "\n",
    "# Normalizar las columnas numéricas\n",
    "numerical_columns = ['total_onshift_partners', 'total_busy_partners', 'total_outstanding_orders', 'order_hour']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numerical_data_scaled = scaler.fit_transform(df_cleaned[numerical_columns])\n",
    "\n",
    "# Concatenar todas las características preprocesadas\n",
    "X_processed = pd.concat([pd.DataFrame(order_day_encoded), \n",
    "                         pd.DataFrame(grouped_category_encoded), \n",
    "                         pd.DataFrame(numerical_data_scaled)], axis=1)\n",
    "\n",
    "# Variable objetivo (delivery_duration)\n",
    "y_processed = df_cleaned['delivery_duration']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y_processed, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar el modelo de Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "modelo_rf = RandomForestRegressor(random_state=42, n_estimators=100, max_depth=10)\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_rf = modelo_rf.predict(X_test)\n",
    "\n",
    "# Calcular MSE, MAE y R² para el modelo de Random Forest\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "mse_rf, mae_rf, r2_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luismgl/Library/Python/3.9/lib/python/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'modelo__learning_rate': 0.1, 'modelo__max_depth': 7, 'modelo__n_estimators': 200, 'modelo__subsample': 0.8}\n",
      "MSE: 685868.0877393779\n",
      "MAE: 640.785326836029\n",
      "R²: 0.26538816635711193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Definir las columnas categóricas y numéricas\n",
    "columnas_categoricas = ['order_day', 'grouped_category']\n",
    "columnas_numericas = ['order_hour', 'total_onshift_partners', 'total_busy_partners', 'total_outstanding_orders']\n",
    "\n",
    "# Preprocesamiento\n",
    "preprocesador = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), columnas_categoricas),\n",
    "        ('num', StandardScaler(), columnas_numericas)\n",
    "    ])\n",
    "\n",
    "# Definir el modelo\n",
    "modelo = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Crear el pipeline\n",
    "pipeline = Pipeline(steps=[('preprocesamiento', preprocesador),\n",
    "                           ('modelo', modelo)])\n",
    "\n",
    "# Definir el espacio de búsqueda para los hiperparámetros\n",
    "parametros = {\n",
    "    'modelo__n_estimators': [100, 200, 300],\n",
    "    'modelo__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'modelo__max_depth': [3, 5, 7],\n",
    "    'modelo__subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X = df_delivery[['order_day', 'grouped_category', 'order_hour', 'total_onshift_partners', 'total_busy_partners', 'total_outstanding_orders']]\n",
    "y = df_delivery['delivery_duration']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar GridSearchCV con validación cruzada\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=parametros, cv=5, n_jobs=-1, scoring='r2')\n",
    "\n",
    "# Entrenar el modelo con GridSearch\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores parámetros encontrados\n",
    "mejores_parametros = grid_search.best_params_\n",
    "print(\"Mejores parámetros:\", mejores_parametros)\n",
    "\n",
    "# Evaluar el modelo con los mejores parámetros\n",
    "mejor_modelo = grid_search.best_estimator_\n",
    "y_pred = mejor_modelo.predict(X_test)\n",
    "\n",
    "# Calcular MSE, MAE y R² para el modelo ajustado\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R²:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END modelo__learning_rate=0.05, modelo__max_depth=7, modelo__n_estimators=200, modelo__subsample=0.9; total time=  33.9s\n",
      "[CV] END modelo__learning_rate=0.05, modelo__max_depth=7, modelo__n_estimators=200, modelo__subsample=0.9; total time=  34.3s\n",
      "[CV] END modelo__learning_rate=0.05, modelo__max_depth=7, modelo__n_estimators=200, modelo__subsample=0.9; total time=  34.3s\n",
      "[CV] END modelo__learning_rate=0.05, modelo__max_depth=7, modelo__n_estimators=200, modelo__subsample=0.9; total time=  34.3s\n",
      "[CV] END modelo__learning_rate=0.1, modelo__max_depth=9, modelo__n_estimators=200, modelo__subsample=0.9; total time=  48.1s\n",
      "[CV] END modelo__learning_rate=0.1, modelo__max_depth=9, modelo__n_estimators=200, modelo__subsample=0.9; total time=  48.1s\n",
      "[CV] END modelo__learning_rate=0.1, modelo__max_depth=9, modelo__n_estimators=200, modelo__subsample=0.9; total time=  48.4s\n",
      "[CV] END modelo__learning_rate=0.1, modelo__max_depth=9, modelo__n_estimators=200, modelo__subsample=0.9; total time=  48.8s\n",
      "[CV] END modelo__learning_rate=0.1, modelo__max_depth=9, modelo__n_estimators=200, modelo__subsample=0.9; total time=  49.0s\n",
      "[CV] END modelo__learning_rate=0.05, modelo__max_depth=7, modelo__n_estimators=200, modelo__subsample=0.9; total time=  33.6s\n",
      "[CV] END modelo__learning_rate=0.1, modelo__max_depth=5, modelo__n_estimators=200, modelo__subsample=1.0; total time=  21.7s\n",
      "[CV] END modelo__learning_rate=0.1, modelo__max_depth=5, modelo__n_estimators=200, modelo__subsample=1.0; total time=  21.6s\n",
      "[CV] END modelo__learning_rate=0.1, modelo__max_depth=5, modelo__n_estimators=200, modelo__subsample=1.0; total time=  21.8s\n",
      "[CV] END modelo__learning_rate=0.1, modelo__max_depth=5, modelo__n_estimators=200, modelo__subsample=1.0; total time=  21.7s\n",
      "[CV] END modelo__learning_rate=0.1, modelo__max_depth=5, modelo__n_estimators=200, modelo__subsample=1.0; total time=  21.7s\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=9, modelo__n_estimators=500, modelo__subsample=0.8; total time= 2.1min\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=9, modelo__n_estimators=500, modelo__subsample=0.8; total time= 2.1min\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=9, modelo__n_estimators=500, modelo__subsample=0.8; total time= 2.1min\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=9, modelo__n_estimators=500, modelo__subsample=0.8; total time= 2.1min\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=9, modelo__n_estimators=500, modelo__subsample=0.8; total time= 2.2min\n",
      "[CV] END modelo__learning_rate=0.2, modelo__max_depth=7, modelo__n_estimators=500, modelo__subsample=0.8; total time= 1.2min\n",
      "[CV] END modelo__learning_rate=0.2, modelo__max_depth=7, modelo__n_estimators=500, modelo__subsample=0.8; total time= 1.3min\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=5, modelo__n_estimators=200, modelo__subsample=0.8; total time=  20.6s\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=5, modelo__n_estimators=200, modelo__subsample=0.8; total time=  20.9s\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=5, modelo__n_estimators=200, modelo__subsample=0.8; total time=  20.9s\n",
      "[CV] END modelo__learning_rate=0.1, modelo__max_depth=9, modelo__n_estimators=500, modelo__subsample=1.0; total time= 1.9min\n",
      "[CV] END modelo__learning_rate=0.1, modelo__max_depth=9, modelo__n_estimators=500, modelo__subsample=1.0; total time= 1.9min\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=5, modelo__n_estimators=200, modelo__subsample=0.8; total time=  21.2s\n",
      "[CV] END modelo__learning_rate=0.1, modelo__max_depth=9, modelo__n_estimators=500, modelo__subsample=1.0; total time= 1.9min\n",
      "[CV] END modelo__learning_rate=0.1, modelo__max_depth=9, modelo__n_estimators=500, modelo__subsample=1.0; total time= 1.9min\n",
      "[CV] END modelo__learning_rate=0.2, modelo__max_depth=7, modelo__n_estimators=500, modelo__subsample=0.8; total time= 1.2min\n",
      "[CV] END modelo__learning_rate=0.1, modelo__max_depth=9, modelo__n_estimators=500, modelo__subsample=1.0; total time= 1.9min\n",
      "[CV] END modelo__learning_rate=0.2, modelo__max_depth=7, modelo__n_estimators=500, modelo__subsample=0.8; total time= 1.2min\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=5, modelo__n_estimators=200, modelo__subsample=0.8; total time=  20.8s\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=5, modelo__n_estimators=200, modelo__subsample=0.9; total time=  22.6s\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=5, modelo__n_estimators=200, modelo__subsample=0.9; total time=  22.7s\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=5, modelo__n_estimators=200, modelo__subsample=0.9; total time=  22.5s\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=5, modelo__n_estimators=300, modelo__subsample=0.8; total time=  30.8s\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=5, modelo__n_estimators=300, modelo__subsample=0.8; total time=  30.5s\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=5, modelo__n_estimators=300, modelo__subsample=0.8; total time=  30.4s\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=5, modelo__n_estimators=300, modelo__subsample=0.8; total time=  30.4s\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=5, modelo__n_estimators=300, modelo__subsample=0.8; total time=  30.3s\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=5, modelo__n_estimators=200, modelo__subsample=0.9; total time=  21.1s\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=5, modelo__n_estimators=200, modelo__subsample=0.9; total time=  21.1s\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=3, modelo__n_estimators=500, modelo__subsample=0.8; total time=  26.3s\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=3, modelo__n_estimators=500, modelo__subsample=0.8; total time=  26.1s\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=3, modelo__n_estimators=500, modelo__subsample=0.8; total time=  26.0s\n",
      "[CV] END modelo__learning_rate=0.2, modelo__max_depth=7, modelo__n_estimators=500, modelo__subsample=0.8; total time= 1.2min\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=3, modelo__n_estimators=500, modelo__subsample=0.8; total time=  24.5s\n",
      "[CV] END modelo__learning_rate=0.01, modelo__max_depth=3, modelo__n_estimators=500, modelo__subsample=0.8; total time=  24.6s\n",
      "Mejores parámetros: {'modelo__subsample': 0.8, 'modelo__n_estimators': 500, 'modelo__max_depth': 9, 'modelo__learning_rate': 0.01}\n",
      "MSE: 683831.3152683289\n",
      "MAE: 640.705500726773\n",
      "R²: 0.26756968957771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Definir el espacio de búsqueda para los hiperparámetros\n",
    "parametros = {\n",
    "    'modelo__n_estimators': [100, 200, 300, 500],\n",
    "    'modelo__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'modelo__max_depth': [3, 5, 7, 9],\n",
    "    'modelo__subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Inicializar el modelo de GradientBoostingRegressor con los mismos parámetros previos\n",
    "modelo = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Crear el pipeline\n",
    "pipeline = Pipeline(steps=[('preprocesamiento', preprocesador),\n",
    "                           ('modelo', modelo)])\n",
    "\n",
    "# Inicializar RandomizedSearchCV con validación cruzada\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=parametros, n_iter=10, cv=5, verbose=2, n_jobs=-1, scoring='r2', random_state=42)\n",
    "\n",
    "# Entrenar el modelo con RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores parámetros encontrados\n",
    "mejores_parametros = random_search.best_params_\n",
    "print(\"Mejores parámetros:\", mejores_parametros)\n",
    "\n",
    "# Evaluar el modelo con los mejores parámetros\n",
    "mejor_modelo = random_search.best_estimator_\n",
    "y_pred = mejor_modelo.predict(X_test)\n",
    "\n",
    "# Calcular MSE, MAE y R² para el modelo ajustado\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R²:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grouped_category            0\n",
       "total_onshift_partners      0\n",
       "total_busy_partners         0\n",
       "total_outstanding_orders    0\n",
       "order_hour                  0\n",
       "order_day                   0\n",
       "delivery_duration           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionar solo las características relevantes para el modelo\n",
    "caracteristicas_relevantes = [\n",
    "    'grouped_category', 'total_onshift_partners', 'total_busy_partners', 'total_outstanding_orders', \n",
    "    'order_hour', 'order_day'\n",
    "]\n",
    "\n",
    "# Filtrar el dataframe para que solo contenga las columnas necesarias\n",
    "df_relevantes = df_analisis[caracteristicas_relevantes + ['delivery_duration']]\n",
    "\n",
    "# Verificar si hay valores nulos o atípicos en los datos\n",
    "df_relevantes.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grouped_category</th>\n",
       "      <th>total_onshift_partners</th>\n",
       "      <th>total_busy_partners</th>\n",
       "      <th>total_outstanding_orders</th>\n",
       "      <th>order_hour</th>\n",
       "      <th>order_day</th>\n",
       "      <th>delivery_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American</td>\n",
       "      <td>33.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Friday</td>\n",
       "      <td>3779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mexican</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indian</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Italian</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italian</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2988.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  grouped_category  total_onshift_partners  total_busy_partners  \\\n",
       "0         American                    33.0                 14.0   \n",
       "1          Mexican                     1.0                  2.0   \n",
       "2           Indian                     8.0                  6.0   \n",
       "3          Italian                     5.0                  6.0   \n",
       "4          Italian                     5.0                  5.0   \n",
       "\n",
       "   total_outstanding_orders  order_hour order_day  delivery_duration  \n",
       "0                      21.0          22    Friday             3779.0  \n",
       "1                       2.0          21   Tuesday             4024.0  \n",
       "2                      18.0           0    Monday             1586.0  \n",
       "3                       8.0           3  Thursday             2273.0  \n",
       "4                       7.0           2   Tuesday             2988.0  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrar el dataframe para que solo contenga las columnas necesarias\n",
    "df_final = df_analisis[['grouped_category', 'total_onshift_partners', 'total_busy_partners', \n",
    "                        'total_outstanding_orders', 'order_hour', 'order_day', 'delivery_duration']]\n",
    "\n",
    "# Verificar la estructura de las columnas seleccionadas\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('df_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
